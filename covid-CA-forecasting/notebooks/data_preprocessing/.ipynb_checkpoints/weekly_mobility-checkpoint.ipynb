{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import social distancing\n",
    "#with open('/home/mxenoc/workspace/pickles/RISE/social_distancing_CA.pkl', 'rb') as f:\n",
    "#    social_distancing_CA = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "#social_distancing_CA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import matching cities\n",
    "#with open('/home/mxenoc/workspace/pickles/RISE/matching_cities.pkl', 'rb') as f:\n",
    "#    matching_cities = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/mxenoc/workspace/pickles/RISE/SC_cities.pkl', 'rb') as f:\n",
    "    SC_cities = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get population per city\n",
    "#with open('/home/mxenoc/workspace/pickles/RISE/covid_california.pkl', 'rb') as f:\n",
    "#    covid_california = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "#matching_cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "#social_distancing_CA['origin_census_block_group'] = social_distancing_CA['origin_census_block_group'].astype(str).str[1:]\n",
    "#matching_cities = matching_cities[['census_block_group', 'afact', 'city']]\n",
    "#matching_cities.columns = ['origin_census_block_group', 'afact', 'city']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find_city_devices = pd.merge(social_distancing_CA[['origin_census_block_group', 'date_range_start', 'device_count']], matching_cities, on=\"origin_census_block_group\")\n",
    "#covid_california.columns = ['date_range_start', 'city', 'confirmed_cases', 'population']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find_city_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find_city_devices['device_count_cities'] = find_city_devices['device_count'] * find_city_devices['afact'].astype(float)\n",
    "#find_city_devices = find_city_devices[['date_range_start', 'city', 'device_count_cities']]\n",
    "#find_city_devices = np.round(find_city_devices.groupby(['date_range_start', 'city'], as_index=False)['device_count_cities'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "#city_devices_all = pd.merge(covid_california[['date_range_start', 'city', 'population']], find_city_devices, on = ['date_range_start', 'city'])\n",
    "#city_devices_all.columns = ['date', 'origin_city', 'population', 'device_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import matching cities\n",
    "#with open('/home/mxenoc/workspace/pickles/RISE/city_stats.pkl', 'rb') as f:\n",
    "#    city_devices_all = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/home/mxenoc/workspace/pickles/RISE/social_distancing_days/'\n",
    "files=[]\n",
    "files = [f for f in sorted(os.listdir(root))]\n",
    "regex = re.compile('.ipynb')\n",
    "files = [i for i in files if not regex.match(i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "movement_days = []\n",
    "for file in files: \n",
    "    with open(root+file, 'rb') as f:\n",
    "        movement_days.append(pickle.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep only the traffic that has destination or origin city within SC\n",
    "all_days = pd.concat(movement_days)\n",
    "all_days = all_days[(all_days.origin_city.isin(SC_cities))|(all_days.destination_city.isin(SC_cities))]\n",
    "all_days['origin_destination'] = all_days['origin_city'] + all_days['destination_city']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2020-06-25 00:00:00')"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(all_days['date_range_start'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2020-04-01'\n",
    "end_date = '2020-06-25'\n",
    "all_days = all_days[(all_days['date_range_start'] >= start_date) & (all_days['date_range_start'] <= end_date)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_origins = np.unique(all_days.origin_destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_days = all_days[all_days.date_range_start == '2020-12-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_days = all_days[all_days.origin_city.isin(SC_cities)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.concat([movements_list[movement][['origin_city', 'destination_city']], movements_list[movement].rolling(7).sum()], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divide the df into a list with one df per city\n",
    "movements_list = {}\n",
    "for movement in all_origins:\n",
    "    movements_list[movement] = all_days[all_days.origin_destination == movement]\n",
    "\n",
    "    #Get date range\n",
    "    idx = pd.date_range(start_date, end_date)\n",
    "    #Use dates as indexes\n",
    "    movements_list[movement].index = movements_list[movement]['date_range_start']\n",
    "\n",
    "    #Drop date and place columns\n",
    "    movements_list[movement] = movements_list[movement].drop(['date_range_start', 'device_count_cities', \n",
    "                                                              'moving_devices_new', 'population'], axis = 1)\n",
    "    #Fill in missing dates\n",
    "    movements_list[movement] = movements_list[movement].reindex(idx, fill_value=None)\n",
    "\n",
    "    #Interpolate missing values\n",
    "    movements_list[movement].interpolate(method='linear', inplace=True)\n",
    "\n",
    "    #Get 7-day moving sum (the date is the last date of the 7-day window)\n",
    "    movements_list[movement] = pd.concat([movements_list[movement][['origin_city', 'destination_city']], \n",
    "                                          movements_list[movement].rolling(7).mean()], axis = 1)\n",
    "    #Replace Nas\n",
    "    movements_list[movement] = movements_list[movement].fillna(method='bfill')\n",
    "    movements_list[movement] = movements_list[movement].fillna(method='ffill')\n",
    "    #Remove first and last 6 rows\n",
    "    movements_list[movement] = movements_list[movement][7:]    \n",
    "    \n",
    "    #Bring date column back\n",
    "    movements_list[movement]['date'] = movements_list[movement].index\n",
    "    movements_list[movement].reset_index(inplace=True, drop=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change to dataframe\n",
    "weekly_movements = pd.DataFrame(pd.concat(movements_list))\n",
    "\n",
    "#Normalize per device count and population\n",
    "#weekly_movements_all = pd.merge(city_devices_all, weekly_movements, on = ['origin_city', 'date'])\n",
    "#weekly_movements_all['total_moving_devices'] = (weekly_movements_all['moving_devices_new']/weekly_movements_all['device_count'])*weekly_movements_all['population']\n",
    "#weekly_movements_all = weekly_movements_all[['date', 'origin_city', 'destination_city', 'total_moving_devices']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'weekly_movements_all' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-207-3be3c6c099ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/mxenoc/workspace/pickles/RISE/weekly_movements_SC.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweekly_movements_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'weekly_movements_all' is not defined"
     ]
    }
   ],
   "source": [
    "with open('/home/mxenoc/workspace/pickles/RISE/weekly_movements_SC.pkl', 'wb') as f:  \n",
    "    pickle.dump(weekly_movements, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
