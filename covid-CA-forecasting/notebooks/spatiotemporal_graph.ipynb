{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 922,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_scatter import scatter_mean\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import torch_geometric_temporal\n",
    "from torch_geometric.nn.models.re_net import RENet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 923,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric_temporal.data.splitter import discrete_train_test_split\n",
    "from torch_geometric_temporal.data.discrete.dynamic_graph_discrete_signal import DynamicGraphDiscreteSignal\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#from rise_utils import to_torch_inputs\n",
    "from covid_CA_forecasting import torch_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 924,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/mxenoc/workspace/pickles/RISE/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 925,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing for SC\n",
    "with open(path + 'weekly_movements_SC.pkl', 'rb') as f:\n",
    "    df = pickle.load(f)\n",
    "\n",
    "with open(path + 'weekly_infections.pkl', 'rb') as f:\n",
    "    cc = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 926,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/mxenoc/workspace/pickles/RISE/SC_cities.pkl', 'rb') as f:\n",
    "    SC_cities = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 927,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cities = pd.unique(df[['origin_city', 'destination_city']].values.ravel('K'))\n",
    "all_days = np.unique(df.loc[:,'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 928,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 928,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode city\n",
    "le = LabelEncoder()\n",
    "le.fit(all_cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 929,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = cc[cc['place'].isin(all_cities)]\n",
    "cc = cc[cc['date'].isin(all_days)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 930,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode city for all datasets\n",
    "df['origin_city_encoded'] = le.transform(df['origin_city'])\n",
    "df['destination_city_encoded'] = le.transform(df['destination_city'])\n",
    "cc['city_encoded'] = le.transform(cc['place'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 931,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_data_mean = pd.read_csv('/home/mxenoc/workspace/covid-CA-forecasting/data/census_features/censusFeature_mean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 932,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_data = pd.read_csv('/home/mxenoc/workspace/covid-CA-forecasting/data/census_features/censusFeature.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 933,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_columns = census_data.columns.intersection(census_data_mean.columns).drop('city')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 934,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_data = census_data.drop(common_columns, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 935,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_data_mean = census_data_mean[['city','mean_male_age', 'mean_female_age', 'mean_income', 'mean_pphh', 'mean_B08202', 'mean_B19101',\n",
    "                 'mean_B25014_owner', 'mean_B25014_renter', 'mean_B25017']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 936,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_data = pd.merge(census_data, census_data_mean, on=\"city\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 937,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep only the cities that interact with cities in SC county\n",
    "census_data = census_data[census_data['city'].isin(all_cities)]\n",
    "\n",
    "#Set index to be the encoding of the city\n",
    "census_data['city_encoded'] = le.transform(census_data['city'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 938,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Reindex the index and city column\n",
    "census_data.set_index('city_encoded', inplace=True)\n",
    "census_data = census_data.reindex(le.transform(all_cities))\n",
    "census_data['city'] = le.inverse_transform(census_data.index)\n",
    "#Sort by index \n",
    "census_data = census_data.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1005,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_df = cc.merge(census_data, how='inner', on='city_encoded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1237,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_weeks = np.unique(feature_df['date'])\n",
    "all_weeks = all_weeks[54:319]\n",
    "\n",
    "all_weeks_train = all_weeks[:len(all_weeks)-7]\n",
    "all_weeks_test = all_weeks[:len(all_weeks)-6]\n",
    "#all_weeks_train = all_weeks[:(2*len(all_weeks))//4]\n",
    "#all_weeks_test = all_weeks[(2*len(all_weeks))//4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1213,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_weeks = np.unique(feature_df['date'])\n",
    "\n",
    "all_weeks_train = all_weeks[:-1]\n",
    "all_weeks_test = all_weeks\n",
    "#all_weeks_train = all_weeks[:(2*len(all_weeks))//4]\n",
    "#all_weeks_test = all_weeks[(2*len(all_weeks))//4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "265"
      ]
     },
     "execution_count": 1238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_weeks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "258"
      ]
     },
     "execution_count": 1239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_weeks_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "259"
      ]
     },
     "execution_count": 1240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_weeks_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.datetime64('2020-06-01T00:00:00.000000000')"
      ]
     },
     "execution_count": 1241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_weeks_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.datetime64('2021-02-14T00:00:00.000000000')"
      ]
     },
     "execution_count": 1242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_weeks_test[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1243,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df_train = feature_df[feature_df['date'].isin(all_weeks_train)]\n",
    "feature_df_test = feature_df[feature_df['date'].isin(all_weeks_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1244,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_use = list(census_data.columns.drop('city'))\n",
    "features_to_use.append('new_cases_per1000')\n",
    "\n",
    "#features_to_use = ['new_cases_per1000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1245,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mxenoc/anaconda3/envs/pygeo/lib/python3.7/site-packages/pandas/core/frame.py:4527: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  method=method,\n"
     ]
    }
   ],
   "source": [
    "feature_df_train.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "feature_df_test.replace([np.inf, -np.inf], 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1246,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "feature_list = scaler.fit(feature_df_train[features_to_use])             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1253,
   "metadata": {},
   "outputs": [],
   "source": [
    "choose_set = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1254,
   "metadata": {},
   "outputs": [],
   "source": [
    "if choose_set == 'train':\n",
    "    all_weeks_set = all_weeks_train\n",
    "    feature_df_set = feature_df_train\n",
    "    \n",
    "elif choose_set == 'test': \n",
    "    all_weeks_set = all_weeks_test\n",
    "    feature_df_set = feature_df_test    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1255,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the code for each city\n",
    "cities_codes = cc.reset_index(drop = True)\n",
    "cities_codes = cities_codes[['place', 'city_encoded']]\n",
    "cities_codes = cities_codes.drop_duplicates()\n",
    "codes_SC = cities_codes[cities_codes.place.isin(SC_cities)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1256,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_indices_tensorlist = []\n",
    "edge_weights_tensorlist = []\n",
    "features_tensorlist = []\n",
    "targets_tensorlist = []\n",
    "\n",
    "labels = {}\n",
    "# for one graph\n",
    "for selected_week in all_weeks_set:\n",
    "\n",
    "    # select edges for the date\n",
    "    df_selected = df.loc[df.date==selected_week, :]\n",
    "    df_selected = df_selected.fillna(0)\n",
    "\n",
    "    # select cases and fill NaN value for cases that don't exist in the cities\n",
    "    feature_df_selected = feature_df_set.sort_values(['city_encoded', 'date'])\n",
    "    feature_df_selected = feature_df_selected.loc[feature_df_selected.date==selected_week, :]\n",
    "    feature_df_selected.set_index('city_encoded', inplace=True)\n",
    "    feature_df_selected = feature_df_selected.reindex(le.transform(all_cities))\n",
    "    feature_df_selected['city'] = le.inverse_transform(feature_df_selected.index)\n",
    "    feature_df_selected['date'] = selected_week\n",
    "    feature_df_selected = feature_df_selected.sort_index()\n",
    "    feature_df_selected = feature_df_selected.fillna(0)\n",
    "    \n",
    "    edges_list = [np.array(df_selected['origin_city_encoded']), np.array(df_selected['destination_city_encoded'])]\n",
    "\n",
    "    #edge_indices = torch.tensor(edges_list, dtype=torch.long)\n",
    "    edge_indices = edges_list\n",
    "    \n",
    "    #edge_weights = torch.tensor(np.array(df_selected['total_moving_devices']), dtype=torch.float)\n",
    "    edge_weights = np.array(df_selected['device_count_normalised'])\n",
    "    \n",
    "    feature_list = []\n",
    "    #feature_df = cc_selected.merge(census_data, how='inner', on='city_encoded')\n",
    "\n",
    "    #Transform data\n",
    "    features = scaler.transform(feature_df_selected[features_to_use])\n",
    "    features = pd.DataFrame(features, columns = feature_df_selected[features_to_use].columns)\n",
    "\n",
    "    for i in range(feature_df_selected.shape[0]):\n",
    "        new_features = np.array(features.iloc[i])\n",
    "        \n",
    "        #new_features = np.array(cc_selected.iloc[i,1:8])\n",
    "        feature_list.append(new_features)\n",
    "\n",
    "#    features = np.array(cc_selected['new_cases_per1000'])\n",
    "    \n",
    "    features = feature_list\n",
    "    #targets = np.array(feature_df_selected.loc[feature_df_selected.index.isin(codes_SC['city_encoded']), 'new_cases_per1000_in_10_days'])\n",
    "    targets = np.array(feature_df_selected['new_cases_per1000_in_10_days'])\n",
    "    \n",
    "    edge_indices_tensorlist.append(edge_indices)\n",
    "    edge_weights_tensorlist.append(edge_weights)\n",
    "    features_tensorlist.append(features)\n",
    "    targets_tensorlist.append(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1257,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DynamicGraphDiscreteSignal(edge_indices = edge_indices_tensorlist, edge_weights = edge_weights_tensorlist, features = features_tensorlist, targets = targets_tensorlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1258,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path+choose_set+'_SC_all_14_02.pkl', 'wb') as f:  \n",
    "    pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/mxenoc/workspace/pickles/RISE/'"
      ]
     },
     "execution_count": 1211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 970,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04330999694841679"
      ]
     },
     "execution_count": 970,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean((feature_df_train['new_cases_per1000']-feature_df_train['new_cases_per1000_in_10_days'])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 971,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06061878772217091"
      ]
     },
     "execution_count": 971,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean((feature_df_test.loc[feature_df_test.date == '2021-02-09', 'new_cases_per1000'].values-feature_df_test.loc[feature_df_test.date == '2021-02-09', 'new_cases_per1000_in_10_days'].values)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11636441142660875"
      ]
     },
     "execution_count": 1117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(abs(feature_df_train['new_cases_per1000']-feature_df_train['new_cases_per1000_in_10_days']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1704354728631061"
      ]
     },
     "execution_count": 1264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(abs(feature_df_test.loc[feature_df_test.date == '2021-02-09', 'new_cases_per1000'].values-feature_df_test.loc[feature_df_test.date == '2021-02-09', 'new_cases_per1000_in_10_days'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.datetime64('2021-02-14T00:00:00.000000000')"
      ]
     },
     "execution_count": 1227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_weeks_test[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0.1044, 0.1208, 0.1232, 0.1315, 0.1452, 0.1704"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pygeo",
   "language": "python",
   "name": "pygeo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
