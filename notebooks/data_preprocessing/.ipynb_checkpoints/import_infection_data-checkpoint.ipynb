{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "#import matplotlib.colors as colors\n",
    "import numpy as np\n",
    "#import networkx as nx\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "#import swifter\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# California covid cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Match zipcodes to cities\n",
    "#Read csv file with zipcodes and cities\n",
    "matching_cities = pd.read_csv('/home/mxenoc/workspace/covid-CA-forecasting/data/csv_files/matching_cities.csv',error_bad_lines=False, engine=\"python\")\n",
    "\n",
    "#Delete first row\n",
    "matching_cities = matching_cities.loc[1:,:]\n",
    "#Drop unwanted columns\n",
    "matching_cities.drop(['Unnamed: 0', 'census_block_group', 'afact', 'afact2'], axis = 1, inplace = True)\n",
    "#Drop duplicates\n",
    "matching_cities = matching_cities.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import California covid cases\n",
    "covid_california = pd.read_csv('/home/mxenoc/workspace/covid-CA-forecasting/data/csv_files/latimes_place_totals.csv', error_bad_lines=False, engine=\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_city = covid_california.id.map(matching_cities.set_index('zipcode').city)\n",
    "#Replace with city names for the ones you have the postcode for\n",
    "covid_california['name'] = [covid_california.iloc[i,1] if pd.isnull(id_to_city[i]) else id_to_city[i] for i in range(covid_california.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use this to match LA census areas\n",
    "statistical_areas_LA = pd.read_csv('/home/mxenoc/workspace/RISE/data/Countywide_Statistical_Areas_LA.csv',\n",
    "                                   error_bad_lines=False, engine=\"python\", names=['OBJECTID', 'CITY_TYPE', \n",
    "                                                                                  'LCITY', 'COMMUNITY', 'LABEL', 'SOURCE', \n",
    "                                                                                  'ShapeSTArea', 'ShapeSTLength'])\n",
    "\n",
    "statistical_areas_LA = statistical_areas_LA.loc[1::]\n",
    "statistical_areas_LA['COMMUNITY'].replace(' ', np.nan, inplace=True)\n",
    "statistical_areas_LA = statistical_areas_LA.dropna(subset = ['COMMUNITY'])\n",
    "\n",
    "ids = statistical_areas_LA['COMMUNITY']\n",
    "exclude_duplicates = statistical_areas_LA[ids.isin(ids[ids.duplicated()])]['COMMUNITY']\n",
    "\n",
    "exclude1 = statistical_areas_LA[statistical_areas_LA.COMMUNITY.isin(exclude_duplicates)]\n",
    "exclude2 = exclude1[exclude1.LCITY == 'Unincorporated']\n",
    "\n",
    "statistical_areas_LA = pd.concat([statistical_areas_LA, exclude2]).drop_duplicates(keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the list of places you cannot match\n",
    "all_missing = []\n",
    "counties_california = np.unique(covid_california.county)\n",
    "counties_list = dict()\n",
    "counter = 0\n",
    "for selected_county in counties_california: \n",
    "    covid_county = covid_california.loc[covid_california['county'] == selected_county]\n",
    "    missing_places = np.unique(covid_county['name'][~covid_county['name'].isin(matching_cities['city'])].dropna())\n",
    "    regex = re.compile('unincorporated|Unincorporated|Other|East|North|South|West|Reporting')\n",
    "    missing_places = [i for i in missing_places if not regex.match(i)]\n",
    "    counties_list[selected_county] = missing_places\n",
    "    all_missing += missing_places\n",
    "    counter += len(missing_places)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Match zipcodes to cities for a banch of counties\n",
    "covid_california.loc[covid_california['county'].isin(['Alameda', 'Calaveras','Humboldt', 'Imperial', 'Kern', 'Long Beach', 'Monterey', \n",
    "                          'Nevada', 'Pasadena', 'Placer', 'San Diego', 'San Mateo', 'San Joaquin', 'Sonoma']), 'name'] = covid_california.loc[covid_california['county'].isin(['Alameda', 'Calaveras', 'Humboldt', 'Imperial', 'Kern', 'Long Beach', 'Monterey', \n",
    "                          'Nevada', 'Pasadena', 'Placer', 'San Diego', 'San Mateo', 'San Joaquin', 'Sonoma']), 'name'].str.partition(': ')[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Match more counties\n",
    "covid_california.loc[covid_california['county'].isin(['Tulare']), 'name'] = covid_california.loc[covid_california['county'].isin(['Tulare']), 'name'].str.partition(': ')[0]\n",
    "covid_california.loc[covid_california['county'].isin(['Lake']), 'name'] = covid_california.loc[covid_california['county'].isin(['Lake']), 'name'].map(matching_cities.set_index('zipcode')['city'])\n",
    "covid_california.loc[covid_california['county'].isin(['San Francisco']), 'name'] = covid_california.loc[covid_california['county'].isin(['San Francisco']), 'name'].map(matching_cities.set_index('zipcode')['city'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace only the places that are in both the LA communities and they don't have a match \n",
    "replace_which = statistical_areas_LA.COMMUNITY\n",
    "#\n",
    "replace_places = list(set(all_missing).intersection(statistical_areas_LA.COMMUNITY.tolist()))\n",
    "covid_california.loc[covid_california.name.isin(replace_places), 'name'] = covid_california.loc[covid_california.name.isin(replace_places), 'name'].map(statistical_areas_LA.set_index('COMMUNITY')['LCITY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the list of places you cannot match\n",
    "all_missing = []\n",
    "counties_california = np.unique(covid_california.county)\n",
    "counties_list = dict()\n",
    "counter = 0\n",
    "for selected_county in counties_california: \n",
    "    covid_county = covid_california.loc[covid_california['county'] == selected_county]\n",
    "    missing_places = np.unique(covid_county['name'][~covid_county['name'].isin(matching_cities['city'])].dropna())\n",
    "    regex = re.compile('unincorporated|Unincorporated|Other|East|North|South|West|Reporting')\n",
    "    missing_places = [i for i in missing_places if not regex.match(i)]\n",
    "    counties_list[selected_county] = missing_places\n",
    "    all_missing += missing_places\n",
    "    counter += len(missing_places)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "SC_cities = np.unique(covid_california[covid_california.county == 'Santa Clara']['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/mxenoc/workspace/pickles/RISE/SC_cities.pkl', 'wb') as f:  \n",
    "    pickle.dump(SC_cities, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep the columns you need\n",
    "covid_california = covid_california[['date', 'name', 'confirmed_cases', 'population']]\n",
    "#Drop NAs and duplicates\n",
    "covid_california = covid_california.dropna()\n",
    "covid_california = covid_california.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mxenoc/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Group cases by date and place\n",
    "covid_california = covid_california.groupby(['date', 'name'], as_index=False)['confirmed_cases', 'population'].sum()\n",
    "#Change to date format\n",
    "covid_california[['date']] = pd.to_datetime(covid_california['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep only the places you can match with the mobility data\n",
    "covid_california = covid_california[covid_california.name.isin(matching_cities.city)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>name</th>\n",
       "      <th>confirmed_cases</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2020-02-28</td>\n",
       "      <td>Truckee</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2020-02-29</td>\n",
       "      <td>Truckee</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>Truckee</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2020-03-02</td>\n",
       "      <td>Truckee</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2020-03-03</td>\n",
       "      <td>Truckee</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225414</th>\n",
       "      <td>2021-04-05</td>\n",
       "      <td>Yorba Linda</td>\n",
       "      <td>4108</td>\n",
       "      <td>68706.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225415</th>\n",
       "      <td>2021-04-05</td>\n",
       "      <td>Yountville</td>\n",
       "      <td>144</td>\n",
       "      <td>3032.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225416</th>\n",
       "      <td>2021-04-05</td>\n",
       "      <td>Yuba City</td>\n",
       "      <td>7588</td>\n",
       "      <td>66388.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225417</th>\n",
       "      <td>2021-04-05</td>\n",
       "      <td>Yucaipa</td>\n",
       "      <td>5580</td>\n",
       "      <td>54490.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225418</th>\n",
       "      <td>2021-04-05</td>\n",
       "      <td>Yucca Valley</td>\n",
       "      <td>1475</td>\n",
       "      <td>22146.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156197 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date          name  confirmed_cases  population\n",
       "22     2020-02-28       Truckee                0         0.0\n",
       "26     2020-02-29       Truckee                0         0.0\n",
       "30     2020-03-01       Truckee                0         0.0\n",
       "34     2020-03-02       Truckee                0         0.0\n",
       "38     2020-03-03       Truckee                0         0.0\n",
       "...           ...           ...              ...         ...\n",
       "225414 2021-04-05   Yorba Linda             4108     68706.0\n",
       "225415 2021-04-05    Yountville              144      3032.0\n",
       "225416 2021-04-05     Yuba City             7588     66388.0\n",
       "225417 2021-04-05       Yucaipa             5580     54490.0\n",
       "225418 2021-04-05  Yucca Valley             1475     22146.0\n",
       "\n",
       "[156197 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_california"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/mxenoc/workspace/pickles/RISE/covid_california.pkl', 'wb') as f:  \n",
    "    pickle.dump(covid_california, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2020-03-15'\n",
    "end_date = '2021-04-05'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divide the df into a list with one df per city\n",
    "places_list = {}\n",
    "for place in np.unique(covid_california.name):\n",
    "    places_list[place] = covid_california[covid_california.name == place]\n",
    "    \n",
    "    #Get date range\n",
    "    idx = pd.date_range(start_date, end_date)\n",
    "    #Use dates as indexes\n",
    "    places_list[place].index = pd.DatetimeIndex(places_list[place]['date'])\n",
    "    places_list[place] = places_list[place][['confirmed_cases', 'population', 'name',]]    \n",
    "    #Fill in missing dates\n",
    "    places_list[place] = places_list[place].reindex(idx, fill_value=None)\n",
    "    #Interpolate missing values\n",
    "    places_list[place].interpolate(method='linear', inplace=True)\n",
    "    \n",
    "    #Get cases on next day\n",
    "    confirmed_cases_previousDay = places_list[place]['confirmed_cases'].values[:-1]\n",
    "    #Column with cases next day\n",
    "    places_list[place]['confirmed_cases_previousDay'] = np.insert(confirmed_cases_previousDay,0,0)\n",
    "    #Get new cases \n",
    "    places_list[place]['new_cases'] = places_list[place]['confirmed_cases'] - places_list[place]['confirmed_cases_previousDay']\n",
    "    #If there are any we don't have data for in the start of the time period, make them 0\n",
    "    places_list[place]['new_cases'] = places_list[place]['new_cases'].fillna(0)\n",
    "    #Get new case % based on population\n",
    "    places_list[place]['new_cases_per1000'] = (places_list[place]['new_cases']/places_list[place]['population'])*1000\n",
    "    #Add date and week column\n",
    "    places_list[place]['date'] = places_list[place].index\n",
    "    #Keep only the columns you want \n",
    "    places_list[place] = places_list[place][['new_cases_per1000']]\n",
    "\n",
    "    #Get 7-day moving average (the date is the last date of the 7-day window)\n",
    "    places_list[place] = places_list[place].rolling(7).mean()\n",
    "    \n",
    "    #Add target cases\n",
    "    places_list[place]['new_cases_per1000_in_1_days'] = list(places_list[place]['new_cases_per1000'][1:])+[None]*1\n",
    "    places_list[place]['new_cases_per1000_in_2_days'] = list(places_list[place]['new_cases_per1000'][2:])+[None]*2\n",
    "    places_list[place]['new_cases_per1000_in_3_days'] = list(places_list[place]['new_cases_per1000'][3:])+[None]*3\n",
    "    places_list[place]['new_cases_per1000_in_4_days'] = list(places_list[place]['new_cases_per1000'][4:])+[None]*4\n",
    "    places_list[place]['new_cases_per1000_in_5_days'] = list(places_list[place]['new_cases_per1000'][5:])+[None]*5    \n",
    "    places_list[place]['new_cases_per1000_in_6_days'] = list(places_list[place]['new_cases_per1000'][6:])+[None]*6\n",
    "    places_list[place]['new_cases_per1000_in_7_days'] = list(places_list[place]['new_cases_per1000'][7:])+[None]*7\n",
    "    \n",
    "    places_list[place]['new_cases_per1000_in_10_days'] = list(places_list[place]['new_cases_per1000'][10:])+[None]*10\n",
    "    places_list[place]['new_cases_per1000_in_11_days'] = list(places_list[place]['new_cases_per1000'][11:])+[None]*11\n",
    "    places_list[place]['new_cases_per1000_in_12_days'] = list(places_list[place]['new_cases_per1000'][12:])+[None]*12\n",
    "    places_list[place]['new_cases_per1000_in_13_days'] = list(places_list[place]['new_cases_per1000'][13:])+[None]*13\n",
    "    places_list[place]['new_cases_per1000_in_14_days'] = list(places_list[place]['new_cases_per1000'][14:])+[None]*14\n",
    "    places_list[place]['new_cases_per1000_in_15_days'] = list(places_list[place]['new_cases_per1000'][15:])+[None]*15\n",
    "    places_list[place]['new_cases_per1000_in_16_days'] = list(places_list[place]['new_cases_per1000'][16:])+[None]*16\n",
    "    places_list[place]['new_cases_per1000_in_17_days'] = list(places_list[place]['new_cases_per1000'][17:])+[None]*17\n",
    "\n",
    "    #Remove Nas\n",
    "    places_list[place] = places_list[place].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note that population varies depending on how many places in the city we have data for at each date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change to dataframe\n",
    "weekly_infections = pd.DataFrame(pd.concat(places_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get column date from index\n",
    "weekly_infections['place'] = [i[0] for i in weekly_infections.index]\n",
    "weekly_infections['date'] = [i[1] for i in weekly_infections.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/mxenoc/workspace/pickles/RISE/weekly_infections.pkl', 'wb') as f:  \n",
    "    pickle.dump(weekly_infections, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_infections_SC = weekly_infections[weekly_infections.place.isin(SC_cities)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/mxenoc/workspace/pickles/RISE/weekly_infections_SC.pkl', 'wb') as f:  \n",
    "    pickle.dump(weekly_infections_SC, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
